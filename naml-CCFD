{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242fdbd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:58:48.676041Z",
     "iopub.status.busy": "2025-03-12T10:58:48.675811Z",
     "iopub.status.idle": "2025-03-12T10:58:54.240356Z",
     "shell.execute_reply": "2025-03-12T10:58:54.239507Z"
    },
    "papermill": {
     "duration": 5.57016,
     "end_time": "2025-03-12T10:58:54.241928",
     "exception": false,
     "start_time": "2025-03-12T10:58:48.671768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8609458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:58:54.249193Z",
     "iopub.status.busy": "2025-03-12T10:58:54.248857Z",
     "iopub.status.idle": "2025-03-12T10:58:57.220009Z",
     "shell.execute_reply": "2025-03-12T10:58:57.219296Z"
    },
    "papermill": {
     "duration": 2.976007,
     "end_time": "2025-03-12T10:58:57.221472",
     "exception": false,
     "start_time": "2025-03-12T10:58:54.245465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Load and preprocess dataset\n",
    "# -----------------------------\n",
    "data = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n",
    "dataset = data.to_numpy().astype(np.float32)\n",
    "\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf29ee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:58:57.228310Z",
     "iopub.status.busy": "2025-03-12T10:58:57.228055Z",
     "iopub.status.idle": "2025-03-12T10:58:57.285035Z",
     "shell.execute_reply": "2025-03-12T10:58:57.284306Z"
    },
    "papermill": {
     "duration": 0.061946,
     "end_time": "2025-03-12T10:58:57.286576",
     "exception": false,
     "start_time": "2025-03-12T10:58:57.224630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy X to X_scaled so that we can replace only specific columns\n",
    "X_scaled = X.copy()\n",
    "\n",
    "# Use RobustScaler on columns 0 and 29\n",
    "scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), unit_variance=False)\n",
    "X_scaled[:, [0, 29]] = scaler.fit_transform(X[:, [0, 29]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d227831c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:58:57.293471Z",
     "iopub.status.busy": "2025-03-12T10:58:57.293194Z",
     "iopub.status.idle": "2025-03-12T10:58:57.330117Z",
     "shell.execute_reply": "2025-03-12T10:58:57.329386Z"
    },
    "papermill": {
     "duration": 0.041965,
     "end_time": "2025-03-12T10:58:57.331737",
     "exception": false,
     "start_time": "2025-03-12T10:58:57.289772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split entire dataset into train and test\n",
    "data_train, data_test, label_train, label_test = train_test_split(X_scaled, y, test_size=0.3, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343bc643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:58:57.338776Z",
     "iopub.status.busy": "2025-03-12T10:58:57.338521Z",
     "iopub.status.idle": "2025-03-12T10:58:57.343943Z",
     "shell.execute_reply": "2025-03-12T10:58:57.343295Z"
    },
    "papermill": {
     "duration": 0.010121,
     "end_time": "2025-03-12T10:58:57.345212",
     "exception": false,
     "start_time": "2025-03-12T10:58:57.335091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. Define the Autoencoder Model\n",
    "# -----------------------------\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder: 30 -> 23 -> 19 -> 17 -> 8\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(30, 23),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(23, 19),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(19, 17),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(17, 8)\n",
    "        )\n",
    "        # Decoder: 8 -> 17 -> 19 -> 23 -> 30 with Sigmoid at the end\n",
    "        # (Sigmoid is optional if you are using MSELoss and inputs are not strictly [0,1])\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 17),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(17, 19),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(19, 23),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(23, 30)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c1a7b3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-12T10:58:57.351733Z",
     "iopub.status.busy": "2025-03-12T10:58:57.351519Z",
     "iopub.status.idle": "2025-03-12T10:59:33.271902Z",
     "shell.execute_reply": "2025-03-12T10:59:33.271008Z"
    },
    "papermill": {
     "duration": 35.925066,
     "end_time": "2025-03-12T10:59:33.273215",
     "exception": false,
     "start_time": "2025-03-12T10:58:57.348149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 28.2226, Val Loss: 30.1316\n",
      "Epoch 50, Train Loss: 8.3753, Val Loss: 6.8935\n",
      "Epoch 100, Train Loss: 7.8159, Val Loss: 6.6469\n",
      "Epoch 150, Train Loss: 7.4674, Val Loss: 6.2882\n",
      "Epoch 200, Train Loss: 7.2326, Val Loss: 5.8402\n",
      "Epoch 250, Train Loss: 6.8539, Val Loss: 5.5352\n",
      "Epoch 300, Train Loss: 6.7555, Val Loss: 5.2940\n",
      "Epoch 350, Train Loss: 6.6193, Val Loss: 5.0581\n",
      "Epoch 400, Train Loss: 6.4841, Val Loss: 4.6275\n",
      "Epoch 450, Train Loss: 6.4948, Val Loss: 4.5604\n",
      "Epoch 500, Train Loss: 6.3811, Val Loss: 4.4412\n",
      "Epoch 550, Train Loss: 6.2286, Val Loss: 4.3425\n",
      "Epoch 600, Train Loss: 6.1312, Val Loss: 4.2424\n",
      "Epoch 650, Train Loss: 6.2141, Val Loss: 4.2627\n",
      "Epoch 700, Train Loss: 6.1975, Val Loss: 4.4689\n",
      "Epoch 750, Train Loss: 6.1276, Val Loss: 4.2197\n",
      "Epoch 800, Train Loss: 6.0792, Val Loss: 4.3619\n",
      "Early stopping at epoch 825\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Extract fraud samples using label_train (1 = fraud)\n",
    "# -----------------------------\n",
    "# data_train and label_train are assumed to be already defined from your previous splitting.\n",
    "data_train_fraud = data_train[label_train == 1]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Train/Validation Split (80-20) on the fraud samples\n",
    "# -----------------------------\n",
    "data_train_autoencoder, test_data_autoencoder = train_test_split(data_train_fraud, test_size=0.2, random_state=32)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors (ensure float type)\n",
    "tensor_fraud_train = torch.from_numpy(data_train_autoencoder).float()\n",
    "tensor_fraud_val   = torch.from_numpy(test_data_autoencoder).float()\n",
    "\n",
    "# For an autoencoder, input equals target\n",
    "train_dataset = TensorDataset(tensor_fraud_train, tensor_fraud_train)\n",
    "val_dataset   = TensorDataset(tensor_fraud_val, tensor_fraud_val)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Initialize Model, Loss, Optimizer, and Scheduler\n",
    "# -----------------------------\n",
    "my_autoencoder = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()  # Using MSELoss now\n",
    "optimizer = optim.AdamW(my_autoencoder.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500, eta_min=1e-6)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Training Loop with L1 Regularization and Validation Evaluation\n",
    "# -----------------------------\n",
    "num_epochs = 2000\n",
    "history_loss_train = []\n",
    "history_loss_val   = []\n",
    "patience = 75\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "l1_lambda = 5e-3  # L1 regularization strength\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    my_autoencoder.train()\n",
    "    running_loss_train = 0.0\n",
    "    for batch_x, _ in train_loader:\n",
    "        inputs = batch_x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = my_autoencoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        \n",
    "        # Compute L1 norm of the model parameters\n",
    "        l1_norm = sum(p.abs().sum() for p in my_autoencoder.parameters())\n",
    "        loss = loss + l1_lambda * l1_norm\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss_train += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss_train = running_loss_train / len(train_loader.dataset)\n",
    "    history_loss_train.append(epoch_loss_train)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    my_autoencoder.eval()\n",
    "    running_loss_val = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, _ in val_loader:\n",
    "            inputs = batch_x.to(device)\n",
    "            outputs = my_autoencoder(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            running_loss_val += loss.item() * inputs.size(0)\n",
    "    epoch_loss_val = running_loss_val / len(val_loader.dataset)\n",
    "    history_loss_val.append(epoch_loss_val)\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_loss_val < best_val_loss:\n",
    "        best_val_loss = epoch_loss_val\n",
    "        best_model_state = my_autoencoder.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        my_autoencoder.load_state_dict(best_model_state)\n",
    "        break\n",
    "\n",
    "    # Optionally step the scheduler\n",
    "    # scheduler.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {epoch_loss_train:.4f}, Val Loss: {epoch_loss_val:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(my_autoencoder.state_dict(), \"autoencoder.pth\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Plot Training & Validation Loss\n",
    "# -----------------------------\n",
    "plt.figure()\n",
    "plt.plot(history_loss_train, label='Train Loss')\n",
    "plt.plot(history_loss_val, label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Log Scale)\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e293deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T10:59:33.283091Z",
     "iopub.status.busy": "2025-03-12T10:59:33.282726Z",
     "iopub.status.idle": "2025-03-12T10:59:33.310923Z",
     "shell.execute_reply": "2025-03-12T10:59:33.310021Z"
    },
    "papermill": {
     "duration": 0.034593,
     "end_time": "2025-03-12T10:59:33.312366",
     "exception": false,
     "start_time": "2025-03-12T10:59:33.277773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9679\n",
      "Test Accuracy: 0.9398\n"
     ]
    }
   ],
   "source": [
    "# create the balanced dataset to train the SVM model\n",
    "data_train_non_fraud = data_train[label_train == 0][:len(data_train_fraud)]\n",
    "\n",
    "# Combine the selected data\n",
    "X_balanced_SVM = np.vstack((data_train_non_fraud, data_train_fraud))\n",
    "y_balanced_SVM = np.hstack((np.zeros(len(data_train_fraud)), np.ones(len(data_train_fraud))))  # Create labels: 0 for non-fraud, 1 for fraud\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_idx = np.random.permutation(len(X_balanced_SVM))\n",
    "X_balanced_SVM = X_balanced_SVM[shuffle_idx]\n",
    "y_balanced_SVM = y_balanced_SVM[shuffle_idx]\n",
    "\n",
    "# Split into training and test sets for SVM\n",
    "data_train_SVM, data_test_SVM, label_train_SVM, label_test_SVM = train_test_split(X_balanced_SVM, y_balanced_SVM, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM model for validation in the oversampling process\n",
    "my_svm = SVC(kernel='linear', C=1.0)\n",
    "my_svm.fit(data_train_SVM, label_train_SVM)\n",
    "\n",
    "# Get predictions and accuracy\n",
    "label_pred_test = my_svm.predict(data_test_SVM)\n",
    "label_pred_train = my_svm.predict(data_train_SVM)\n",
    "accuracy_train = np.mean(label_pred_train == label_train_SVM)\n",
    "accuracy_test = np.mean(label_pred_test == label_test_SVM)\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f405506",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-12T10:59:33.322816Z",
     "iopub.status.busy": "2025-03-12T10:59:33.322576Z",
     "iopub.status.idle": "2025-03-12T11:00:19.541756Z",
     "shell.execute_reply": "2025-03-12T11:00:19.540755Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 46.226263,
     "end_time": "2025-03-12T11:00:19.543507",
     "exception": false,
     "start_time": "2025-03-12T10:59:33.317244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial counts - Fraud: 331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 1231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 1531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 1831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 2131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 2431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 2731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 3031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 3331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 3631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 3931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 4231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 4531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 4831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 5131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 5431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 5731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 6031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 6331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 6631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 6931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 7231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 7531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 7831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 8131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 8431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 8731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 9031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 9331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 9631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 9931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 10231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 10531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 10831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 11131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 11431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 11731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 12031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 12331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 12631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 12931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 13231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 13531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 13831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 14131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 14431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 14731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 15031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 15331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 15631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 15931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 16231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 16531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 16831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 17131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 17431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 17731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 18031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 18331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 18631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 18931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 19231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 19531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 19831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 20131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 20431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 20731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 21031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 21331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 21631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 21931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 22231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 22531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 22831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 23131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 23431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 23731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 24031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 24331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 24631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 24931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 25231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 25531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 25831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 26131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 26431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 26731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 27031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 27331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 27631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 27931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 28231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 28531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 28831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 29131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 29431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 29731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 30031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 30331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 30631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 30931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 31231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 31531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 31831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 32131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 32431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 32731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 33031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 33331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 33631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 33931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 34231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 34531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 34831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 35131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 35431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 35731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 36031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 36331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 36631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 36931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 37231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 37531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 37831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 38131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 38431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 38731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 39031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 39331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 39631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 39931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 40231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 40531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 40831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 41131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 41431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 41731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 42031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 42331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 42631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 42931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 43231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 43531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 43831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 44131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 44431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 44731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 45031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 45331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 45631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 45931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 46231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 46531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 46831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 47131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 47431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 47731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 48031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 48331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 48631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 48931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 49231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 49531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 49831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 50131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 50431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 50731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 51031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 51331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 51631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 51931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 52231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 52531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 52831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 53131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 53431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 53731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 54031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 54331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 54631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 54931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 55231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 55531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 55831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 56131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 56431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 56731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 57031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 57331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 57631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 57931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 58231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 58531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 58831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 59131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 59431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 59731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 60031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 60331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 60631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 60931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 61231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 61531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 61831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 62131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 62431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 62731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 63031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 63331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 63631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 63931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 64231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 64531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 64831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 65131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 65431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 65731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 66031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 66331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 66631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 66931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 67231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 67531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 67831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 68131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 68431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 68731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 69031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 69331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 69631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 69931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 70231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 70531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 70831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 71131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 71431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 71731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 72031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 72331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 72631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 72931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 73231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 73531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 73831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 74131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 74431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 74731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 75031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 75331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 75631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 75931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 76231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 76531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 76831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 77131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 77431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 77731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 78031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 78331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 78631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 78931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 79231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 79531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 79831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 80131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 80431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 80731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 81031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 81331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 81631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 81931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 82231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 82531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 82831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 83131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 83431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 83731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 84031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 84331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 84631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 84931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 85231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 85531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 85831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 86131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 86431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 86731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 87031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 87331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 87631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 87931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 88231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 88531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 88831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 89131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 89431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 89731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 90031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 90331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 90631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 90931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 91231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 91531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 91831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 92131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 92431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 92731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 93031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 93331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 93631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 93931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 94231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 94531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 94831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 95131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 95431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 95731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 96031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 96331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 96631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 96931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 97231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 97531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 97831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 98131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 98431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 98731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 99031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 99331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 99631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 99931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 100231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 100531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 100831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 101131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 101431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 101731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 102031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 102331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 102631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 102931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 103231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 103531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 103831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 104131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 104431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 104731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 105031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 105331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 105631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 105931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 106231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 106531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 106831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 107131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 107431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 107731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 108031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 108331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 108631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 108931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 109231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 109531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 109831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 110131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 110431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 110731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 111031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 111331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 111631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 111931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 112231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 112531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 112831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 113131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 113431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 113731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 114031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 114331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 114631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 114931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 115231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 115531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 115831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 116131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 116431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 116731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 117031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 117331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 117631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 117931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 118231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 118531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 118831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 119131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 119431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 119731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 120031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 120331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 120631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 120931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 121231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 121531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 121831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 122131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 122431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 122731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 123031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 123331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 123631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 123931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 124231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 124531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 124831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 125131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 125431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 125731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 126031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 126331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 126631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 126931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 127231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 127531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 127831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 128131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 128431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 128731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 129031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 129331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 129631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 129931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 130231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 130531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 130831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 131131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 131431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 131731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 132031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 132331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 132631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 132931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 133231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 133531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 133831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 134131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 134431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 134731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 135031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 135331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 135631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 135931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 136231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 136531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 136831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 137131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 137431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 137731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 138031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 138331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 138631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 138931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 139231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 139531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 139831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 140131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 140431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 140731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 141031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 141331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 141631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 141931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 142231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 142531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 142831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 143131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 143431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 143731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 144031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 144331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 144631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 144931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 145231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 145531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 145831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 146131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 146431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 146731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 147031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 147331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 147631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 147931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 148231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 148531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 148831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 149131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 149431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 149731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 150031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 150331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 150631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 150931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 151231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 151531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 151831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 152131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 152431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 152731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 153031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 153331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 153631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 153931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 154231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 154531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 154831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 155131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 155431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 155731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 156031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 156331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 156631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 156931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 157231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 157531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 157831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 158131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 158431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 158731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 159031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 159331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 159631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 159931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 160231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 160531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 160831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 161131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 161431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 161731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 162031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 162331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 162631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 162931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 163231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 163531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 163831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 164131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 164431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 164731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 165031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 165331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 165631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 165931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 166231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 166531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 166831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 167131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 167431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 167731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 168031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 168331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 168631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 168931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 169231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 169531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 169831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 170131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 170431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 170731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 171031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 171331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 171631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 171931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 172231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 172531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 172831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 173131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 173431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 173731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 174031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 174331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 174631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 174931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 175231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 175531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 175831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 176131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 176431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 176731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 177031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 177331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 177631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 177931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 178231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 178531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 178831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 179131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 179431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 179731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 180031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 180331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 180631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 180931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 181231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 181531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 181831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 182131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 182431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 182731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 183031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 183331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 183631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 183931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 184231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 184531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 184831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 185131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 185431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 185731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 186031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 186331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 186631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 186931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 187231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 187531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 187831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 188131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 188431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 188731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 189031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 189331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 189631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 189931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 190231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 190531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 190831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 191131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 191431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 191731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 192031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 192331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 192631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 192931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 193231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 193531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 193831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 194131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 194431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 194731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 195031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 195331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 195631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 195931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 196231, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 196531, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 196831, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 197131, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 197431, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 197731, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 198031, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 198331, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 198631, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 198931, Non-fraud: 199033\n",
      "Added 300 synthetic fraud samples. Now, Fraud: 199231, Non-fraud: 199033\n",
      "Balanced oversampled dataset achieved.\n",
      "Final dataset shape: (398264, 30)\n"
     ]
    }
   ],
   "source": [
    "# Create an oversampled dataset starting with the original training data\n",
    "oversampled_data = data_train.copy()    # features only\n",
    "oversampled_labels = label_train.copy()   # corresponding labels\n",
    "\n",
    "# For oversampling, we want to add synthetic fraud samples until fraud count equals non-fraud count.\n",
    "non_fraud_count = np.sum(oversampled_labels == 0)\n",
    "fraud_count = np.sum(oversampled_labels == 1)\n",
    "print(f\"Initial counts - Fraud: {fraud_count}, Non-fraud: {non_fraud_count}\")\n",
    "\n",
    "# Number of synthetic samples to generate per iteration and noise std\n",
    "n_samples_per_iter = 300\n",
    "alpha = 0.9  # standard deviation for Gaussian noise\n",
    "\n",
    "# Use only the original fraud samples (from the training set) as the basis for synthetic data generation.\n",
    "original_fraud_data = data_train[label_train == 1]\n",
    "\n",
    "# Ensure the autoencoder is in evaluation mode\n",
    "my_autoencoder.eval()\n",
    "\n",
    "# Continue generating synthetic fraud samples until the oversampled dataset is balanced\n",
    "while fraud_count < non_fraud_count:\n",
    "    # 1) Encode the original fraud data to the latent space\n",
    "    fraud_tensor = torch.tensor(original_fraud_data, dtype=torch.float32).to(device)\n",
    "    latent_reps = my_autoencoder.encoder(fraud_tensor).detach()\n",
    "    n_fraud_samples = latent_reps.shape[0]\n",
    "    \n",
    "    synthetic_latents = []\n",
    "    # 2) Generate new latent vectors by interpolating between two random latent vectors and adding noise\n",
    "    for _ in range(n_samples_per_iter):\n",
    "        i, j = np.random.choice(n_fraud_samples, size=2, replace=True)\n",
    "        z_i = latent_reps[i]\n",
    "        z_j = latent_reps[j]\n",
    "        lam = np.random.rand()\n",
    "        z_interp = lam * z_i + (1 - lam) * z_j\n",
    "        \n",
    "        # Add Gaussian noise to the interpolated latent vector\n",
    "        noise = torch.normal(mean=0.5, std=alpha, size=z_interp.shape).to(device)\n",
    "        z_syn = z_interp + noise\n",
    "        synthetic_latents.append(z_syn.cpu().numpy())\n",
    "    \n",
    "    synthetic_latents = np.array(synthetic_latents)\n",
    "    synthetic_latents_tensor = torch.tensor(synthetic_latents, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # 3) Decode the synthetic latent vectors to the original feature space\n",
    "    synthetic_data = my_autoencoder.decoder(synthetic_latents_tensor).detach().cpu().numpy()\n",
    "    \n",
    "    # 4) Evaluate the synthetic samples using the trained SVM.\n",
    "    #    Keep only those samples that the SVM predicts as fraud (i.e. label 1)\n",
    "    y_pred = my_svm.predict(synthetic_data)\n",
    "    synthetic_fraud = synthetic_data[y_pred == 1]\n",
    "    \n",
    "    if synthetic_fraud.shape[0] == 0:\n",
    "        print(\"No synthetic fraud samples passed SVM check in this iteration. Trying again...\")\n",
    "        continue\n",
    "    \n",
    "    # 5) Append the accepted synthetic fraud samples to the oversampled dataset.\n",
    "    oversampled_data = np.vstack((oversampled_data, synthetic_fraud))\n",
    "    oversampled_labels = np.hstack((oversampled_labels, np.ones(synthetic_fraud.shape[0])))\n",
    "    \n",
    "    # Update counts\n",
    "    fraud_count = np.sum(oversampled_labels == 1)\n",
    "    non_fraud_count = np.sum(oversampled_labels == 0)\n",
    "    print(f\"Added {synthetic_fraud.shape[0]} synthetic fraud samples. Now, Fraud: {fraud_count}, Non-fraud: {non_fraud_count}\")\n",
    "\n",
    "print(\"Balanced oversampled dataset achieved.\")\n",
    "print(f\"Final dataset shape: {oversampled_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35df70a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T11:00:19.580832Z",
     "iopub.status.busy": "2025-03-12T11:00:19.580415Z",
     "iopub.status.idle": "2025-03-12T11:00:30.819075Z",
     "shell.execute_reply": "2025-03-12T11:00:30.818377Z"
    },
    "papermill": {
     "duration": 11.257352,
     "end_time": "2025-03-12T11:00:30.820729",
     "exception": false,
     "start_time": "2025-03-12T11:00:19.563377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout,Input, Attention, Layer, Concatenate, Permute, Dot, Multiply, Flatten\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=tf.squeeze(tf.tanh(tf.linalg.matmul(x,self.W)+self.b),axis=-1)\n",
    "        at=tf.nn.softmax(et)\n",
    "        at=tf.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return tf.reduce_sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n",
    "\n",
    "def create_ALSTM_model():\n",
    "    inputs1=Input((1,30))\n",
    "    att_in=LSTM(50,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(inputs1)\n",
    "    att_in_1=LSTM(50,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(att_in)\n",
    "    att_out=attention()(att_in_1)\n",
    "    outputs1=Dense(1,activation='sigmoid',trainable=True)(att_out)\n",
    "    model1=Model(inputs1,outputs1)\n",
    "    \n",
    "    model1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e706bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T11:00:30.851035Z",
     "iopub.status.busy": "2025-03-12T11:00:30.850540Z",
     "iopub.status.idle": "2025-03-12T11:00:30.859644Z",
     "shell.execute_reply": "2025-03-12T11:00:30.859012Z"
    },
    "papermill": {
     "duration": 0.025017,
     "end_time": "2025-03-12T11:00:30.860778",
     "exception": false,
     "start_time": "2025-03-12T11:00:30.835761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# --- Adjusted training function using Keras that accepts a validation dataset ---\n",
    "def train_model(model, X, y, num_epochs=2, batch_size=128, val_data=None):\n",
    "    # Ensure X has shape (num_samples, 1, 30)\n",
    "    if X.ndim == 2:\n",
    "        X_train = X.reshape(-1, 1, X.shape[1])\n",
    "    else:\n",
    "        X_train = X\n",
    "\n",
    "    if val_data is not None:\n",
    "        X_val, y_val = val_data\n",
    "        if X_val.ndim == 2:\n",
    "            X_val = X_val.reshape(-1, 1, X_val.shape[1])\n",
    "        val_data = (X_val, y_val)\n",
    "\n",
    "    # Train the model using Keras' fit, including validation monitoring\n",
    "    history = model.fit(X_train, y, epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
    "    return model\n",
    "\n",
    "def GB_classifier(X, y, n_estimators=10, val_data=None):\n",
    "    estimators = []\n",
    "    \n",
    "    # Define squared-error loss (for evaluating the ensemble)\n",
    "    loss_fn = lambda y_true, y_pred: 0.5 * np.sum((y_true - y_pred)**2)\n",
    "    \n",
    "    # Initialize ensemble predictions for training data\n",
    "    # hx = np.full(len(y), np.mean(y), dtype=np.float32)\n",
    "    hx = np.full(len(y), 0, dtype=np.float32)\n",
    "    \n",
    "    # If validation data is provided, initialize ensemble predictions for validation set\n",
    "    if val_data is not None:\n",
    "        X_val, y_val = val_data\n",
    "        hx_val = np.full(len(y_val), np.mean(y_val), dtype=np.float32)\n",
    "    \n",
    "    for t in range(n_estimators):\n",
    "        # Compute training residuals: true labels minus current ensemble predictions\n",
    "        residuals = y - hx\n",
    "        \n",
    "        # For validation, compute residuals using current ensemble prediction if available\n",
    "        if val_data is not None:\n",
    "            residuals_val = y_val - hx_val\n",
    "        \n",
    "        # Create a new instance of the Keras ALSTM model\n",
    "        model_t = create_ALSTM_model()\n",
    "        \n",
    "        # Train the model on (X, residuals) and use validation residuals if provided\n",
    "        if val_data is not None:\n",
    "            train_model(model_t, X, residuals, num_epochs=2, batch_size=128, \n",
    "                        val_data=(X_val, residuals_val))\n",
    "        else:\n",
    "            train_model(model_t, X, residuals, num_epochs=2, batch_size=128)\n",
    "        \n",
    "        # Predict the current weak learner's output h_t on the training set.\n",
    "        X_input = X.reshape(-1, 1, X.shape[1]) if X.ndim == 2 else X\n",
    "        predictions = model_t.predict(X_input)\n",
    "        h_t = predictions.flatten()\n",
    "        \n",
    "        # Use line search to determine the optimal step length alpha\n",
    "        func = lambda alpha: np.sum(loss_fn(y, hx + alpha * h_t))\n",
    "        alpha_t = np.float32(minimize_scalar(func, method=\"golden\").x)\n",
    "        \n",
    "        # Update the ensemble predictions for training data\n",
    "        hx += alpha_t * h_t\n",
    "        \n",
    "        # If validation data is provided, update its ensemble predictions\n",
    "        if val_data is not None:\n",
    "            X_val_input = X_val.reshape(-1, 1, X_val.shape[1]) if X_val.ndim == 2 else X_val\n",
    "            predictions_val = model_t.predict(X_val_input)\n",
    "            h_t_val = predictions_val.flatten()\n",
    "            hx_val += alpha_t * h_t_val\n",
    "        \n",
    "        print(f\"a_{t+1} = {alpha_t:.4f}\")\n",
    "        print(f\"hx_{t+1} = {hx}\")\n",
    "        if val_data is not None:\n",
    "            print(f\"hx_val_{t+1} = {hx_val}\")\n",
    "        \n",
    "        estimators.append((model_t, alpha_t))\n",
    "    \n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd448c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T11:00:30.890469Z",
     "iopub.status.busy": "2025-03-12T11:00:30.890211Z",
     "iopub.status.idle": "2025-03-12T11:08:35.615791Z",
     "shell.execute_reply": "2025-03-12T11:08:35.614677Z"
    },
    "papermill": {
     "duration": 484.743047,
     "end_time": "2025-03-12T11:08:35.617582",
     "exception": false,
     "start_time": "2025-03-12T11:00:30.874535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0219\n",
      "Epoch 2/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 8.9453e-04\n",
      "\u001b[1m12446/12446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step\n",
      "a_1 = 0.9998\n",
      "hx_1 = [7.8299227e-06 2.1561711e-06 6.1794344e-05 ... 9.9975485e-01 9.9975687e-01\n",
      " 9.9975413e-01]\n",
      "Epoch 1/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0190\n",
      "Epoch 2/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 2.8074e-04\n",
      "\u001b[1m12446/12446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step\n",
      "a_2 = 0.3820\n",
      "hx_2 = [5.7154411e-05 6.1714391e-06 1.0590385e-04 ... 9.9975532e-01 9.9976730e-01\n",
      " 9.9976736e-01]\n",
      "Epoch 1/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0189\n",
      "Epoch 2/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 2.5601e-04\n",
      "\u001b[1m12446/12446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step\n",
      "a_3 = -0.0970\n",
      "hx_3 = [5.0797367e-05 5.0008657e-06 8.2299164e-05 ... 9.9975485e-01 9.9976516e-01\n",
      " 9.9976480e-01]\n",
      "Epoch 1/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0185\n",
      "Epoch 2/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 3.2685e-04\n",
      "\u001b[1m12446/12446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step\n",
      "a_4 = -0.0435\n",
      "hx_4 = [4.4147750e-05 4.0319292e-06 7.4772252e-05 ... 9.9975473e-01 9.9976444e-01\n",
      " 9.9976397e-01]\n",
      "Epoch 1/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0182\n",
      "Epoch 2/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 2.9284e-04\n",
      "\u001b[1m12446/12446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step\n",
      "a_5 = 0.1427\n",
      "hx_5 = [6.3683328e-05 6.7775863e-06 9.1536320e-05 ... 9.9975497e-01 9.9976736e-01\n",
      " 9.9976754e-01]\n",
      "Epoch 1/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0173\n",
      "Epoch 2/2\n",
      "\u001b[1m3112/3112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 3.0752e-04\n",
      "\u001b[1m12446/12446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step\n",
      "a_6 = -0.0355\n",
      "hx_6 = [6.1836494e-05 6.4516694e-06 8.9532507e-05 ... 9.9975491e-01 9.9976659e-01\n",
      " 9.9976659e-01]\n"
     ]
    }
   ],
   "source": [
    "estimators = GB_classifier(oversampled_data, oversampled_labels, n_estimators=6, val_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10651743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T11:08:36.469578Z",
     "iopub.status.busy": "2025-03-12T11:08:36.469223Z",
     "iopub.status.idle": "2025-03-12T11:09:15.912020Z",
     "shell.execute_reply": "2025-03-12T11:09:15.911025Z"
    },
    "papermill": {
     "duration": 39.889929,
     "end_time": "2025-03-12T11:09:15.913387",
     "exception": false,
     "start_time": "2025-03-12T11:08:36.023458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
      "Precision: 0.8311\n",
      "Recall: 0.7640\n",
      "F1 Score: 0.7961\n",
      "Accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# Assuming data_test and label_test are defined from your earlier train_test_split\n",
    "# Ensure data_test has shape (n_samples, 1, 30) if needed by the model\n",
    "if data_test.ndim == 2:\n",
    "    data_test_input = data_test.reshape(-1, 1, data_test.shape[1])\n",
    "else:\n",
    "    data_test_input = data_test\n",
    "\n",
    "hx = np.full(len(data_test_input), 0, dtype=np.float32)\n",
    "\n",
    "# Go through each model in the trained ensemble\n",
    "for model, alpha in estimators:\n",
    "    prediction = model.predict(data_test_input).flatten()\n",
    "    hx += alpha * prediction\n",
    "\n",
    "# Threshold the accumulated predictions to get binary outputs\n",
    "y_pred_binary = np.where(hx > 0.5, 1, 0)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(label_test, y_pred_binary)\n",
    "recall = recall_score(label_test, y_pred_binary)\n",
    "f1 = f1_score(label_test, y_pred_binary)\n",
    "accuracy = accuracy_score(label_test, y_pred_binary)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 634.144869,
   "end_time": "2025-03-12T11:09:20.142900",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-12T10:58:45.998031",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
