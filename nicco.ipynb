{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:25:48.186492Z",
     "start_time": "2025-02-28T06:25:46.735844Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "dataset = data.to_numpy().astype(np.float32)\n",
    "\n",
    "scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), unit_variance=False)\n",
    "dataset[:, [0, 29]] = scaler.fit_transform(dataset[:, [0, 29]])\n",
    "\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:, -1]"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into 70% training and 30% testing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:25:48.322558Z",
     "start_time": "2025-02-28T06:25:48.254266Z"
    }
   },
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:25:48.497806Z",
     "start_time": "2025-02-28T06:25:48.485026Z"
    }
   },
   "source": [
    "# -----------------------------\n",
    "# 3. Define the Autoencoder Model\n",
    "# -----------------------------\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder: 31 -> 23 -> 19 -> 17 -> 8 with dropout after first two hidden layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(30, 23),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(23, 19),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(19, 17),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(17, 8)\n",
    "        )\n",
    "        # Decoder: 8 -> 17 -> 19 -> 23 -> 31 with dropout after first two layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 17),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(17, 19),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(19, 23),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(23, 30)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:25:48.610434Z",
     "start_time": "2025-02-28T06:25:48.555712Z"
    }
   },
   "source": [
    "# Get fraud and non-fraud data using y_train\n",
    "fraud_indices = np.where(y_train == 1)[0]\n",
    "non_fraud_indices = np.where(y_train == 0)[0]\n",
    "\n",
    "fraud_data = data_train[fraud_indices]\n",
    "non_fraud_data = data_train[non_fraud_indices]\n",
    "\n",
    "# Calculate number of fraud samples for later use\n",
    "n = len(fraud_data)\n",
    "print(f\"Number of fraud samples in training data: {n}\")\n",
    "\n",
    "# Select an equal number of non-fraud samples\n",
    "non_fraud_data_limited = non_fraud_data[:n]\n",
    "\n",
    "# Combine the selected data\n",
    "X_balanced = np.vstack((non_fraud_data_limited, fraud_data))\n",
    "y_balanced = np.hstack((np.zeros(n), np.ones(n)))  # Create labels: 0 for non-fraud, 1 for fraud\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_idx = np.random.permutation(len(X_balanced))\n",
    "X_balanced_shuffled = X_balanced[shuffle_idx]\n",
    "y_balanced_shuffled = y_balanced[shuffle_idx]\n",
    "\n",
    "# Split into training and test sets for SVM\n",
    "data_train_SVM, data_test_SVM, labels_train_SVM, labels_test_SVM = train_test_split(X_balanced_shuffled, y_balanced_shuffled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM model for validation in the oversampling process\n",
    "model = SVC(kernel='linear', C=1.0)\n",
    "model.fit(data_train_SVM, labels_train_SVM)\n",
    "\n",
    "# Get predictions and accuracy\n",
    "labels_pred_test = model.predict(data_test_SVM)\n",
    "labels_pred_train = model.predict(data_train_SVM)\n",
    "accuracy_train = np.mean(labels_pred_train == labels_train_SVM)\n",
    "accuracy_test = np.mean(labels_pred_test == labels_test_SVM)\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fraud samples in training data: 356\n",
      "Train Accuracy: 0.9455\n",
      "Test Accuracy: 0.9441\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:26:15.379273Z",
     "start_time": "2025-02-28T06:25:48.657185Z"
    }
   },
   "source": [
    "def get_fraud_indices(labels):\n",
    "    \"\"\"Return indices for which label == 1.\"\"\"\n",
    "    return np.where(labels == 1)[0]\n",
    "\n",
    "def get_legit_indices(labels):\n",
    "    \"\"\"Return indices for which label == 0.\"\"\"\n",
    "    return np.where(labels == 0)[0]\n",
    "\n",
    "# Example: placeholders for data_train, y_train\n",
    "# data_train = np.random.randn(100, 30)\n",
    "# y_train    = np.random.randint(0, 2, size=100)\n",
    "\n",
    "# Make your copies to oversample\n",
    "data_train_oversampled = data_train.copy()\n",
    "labels_train_oversampled = y_train.copy()\n",
    "\n",
    "# Load your pre-trained autoencoder\n",
    "autoencoderModel = Autoencoder()\n",
    "autoencoderModel.load_state_dict(\n",
    "    torch.load(\"model/autoencoder/autoencoder30.pth\", map_location=torch.device('cpu'))\n",
    ")\n",
    "autoencoderModel.eval()\n",
    "\n",
    "alpha = 0.9\n",
    "\n",
    "while len(get_fraud_indices(labels_train_oversampled)) < len(get_legit_indices(labels_train_oversampled)):\n",
    "    fraud_indices = get_fraud_indices(labels_train_oversampled)\n",
    "\n",
    "    # Check if we have fraud data to work with\n",
    "    if len(fraud_indices) == 0:\n",
    "        print(\"No fraud data found. Cannot proceed with oversampling.\")\n",
    "        break\n",
    "\n",
    "    # 1) Gather all fraud samples (shape: (num_fraud, 30))\n",
    "    fraud_only_X = data_train_oversampled[fraud_indices, :]\n",
    "    fraud_data_tensor = torch.tensor(fraud_only_X, dtype=torch.float32)\n",
    "\n",
    "    # 2) Encode to latent space\n",
    "    latent_representations = autoencoderModel.encoder(fraud_data_tensor)\n",
    "    n = len(latent_representations)\n",
    "    if n == 0:\n",
    "        print(\"Error: no latent representations. Check input data.\")\n",
    "        break\n",
    "\n",
    "    # 3) Interpolate in latent space + add noise\n",
    "    noisy_vectors = []\n",
    "    for _ in range(300):\n",
    "        i = np.random.randint(0, n)\n",
    "        j = np.random.randint(0, n)\n",
    "\n",
    "        z_i = latent_representations[i]\n",
    "        z_j = latent_representations[j]\n",
    "\n",
    "        lambda_ = np.random.rand()\n",
    "        z_ij = lambda_ * z_i + (1 - lambda_) * z_j\n",
    "\n",
    "        noise = torch.normal(mean=0.0, std=alpha, size=z_ij.shape)\n",
    "        z_syn = z_ij + noise  # shape (8,)\n",
    "\n",
    "        noisy_vectors.append(z_syn.detach().cpu().numpy())\n",
    "\n",
    "    noisy_vectors = np.array(noisy_vectors)  # (300, 8)\n",
    "\n",
    "    # 4) Decode them to original 30-dim space\n",
    "    X_synthetic = autoencoderModel.decoder(\n",
    "        torch.tensor(noisy_vectors, dtype=torch.float32)\n",
    "    ).detach().cpu().numpy()  # shape (300, 30)\n",
    "\n",
    "    # 5) Classify them with your SVM model\n",
    "    #    \"model\" is your trained SVM that does model.predict(...)\n",
    "    y_pred = model.predict(X_synthetic)  # shape (300,)\n",
    "\n",
    "    # 6) Keep only predicted fraud\n",
    "    synthetic_fraud_mask = (y_pred == 1)\n",
    "    X_synthetic_fraud = X_synthetic[synthetic_fraud_mask]\n",
    "    y_synthetic_fraud = y_pred[synthetic_fraud_mask]\n",
    "\n",
    "    # 7) Append these new fraud samples to oversampled data\n",
    "    data_train_oversampled = np.vstack((data_train_oversampled, X_synthetic_fraud))\n",
    "    labels_train_oversampled = np.hstack((labels_train_oversampled, y_synthetic_fraud))\n",
    "\n",
    "    n_fraud = len(get_fraud_indices(labels_train_oversampled))\n",
    "    n_legit = len(get_legit_indices(labels_train_oversampled))\n",
    "    print(f\"New synthetic data generated: {len(X_synthetic_fraud)}\")\n",
    "    print(f\"Number of fraud in the balanced dataset: {n_fraud} / {n_legit}\")\n",
    "\n",
    "print(\"Final shape of data:\", data_train_oversampled.shape)\n",
    "print(\"Final # Fraud:\", len(get_fraud_indices(labels_train_oversampled)))\n",
    "print(\"Final # Legit:\", len(get_legit_indices(labels_train_oversampled)))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 653 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 953 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 1251 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 1549 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 1848 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 2146 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 2445 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 2742 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 3041 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 3340 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 3639 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 3936 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 4234 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 4532 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 4830 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 5127 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 5427 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 5726 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 6026 / 199008\n",
      "New synthetic data generated: 294\n",
      "Number of fraud in the balanced dataset: 6320 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 6617 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 6917 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 7217 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 7515 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 7815 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 8113 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 8413 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 8712 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 9010 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 9309 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 9608 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 9907 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 10207 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 10506 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 10804 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 11101 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 11401 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 11699 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 11998 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 12296 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 12593 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 12891 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 13188 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 13488 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 13788 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 14086 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 14383 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 14682 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 14980 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 15279 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 15577 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 15877 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 16176 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 16476 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 16773 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 17071 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 17370 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 17668 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 17966 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 18264 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 18563 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 18863 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 19162 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 19461 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 19758 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 20057 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 20355 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 20655 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 20953 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 21249 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 21548 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 21847 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 22146 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 22445 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 22745 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 23044 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 23342 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 23642 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 23941 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 24240 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 24540 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 24839 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 25138 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 25437 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 25734 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 26034 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 26333 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 26632 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 26932 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 27232 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 27532 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 27829 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 28129 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 28428 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 28728 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 29026 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 29326 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 29625 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 29924 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 30224 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 30522 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 30821 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 31120 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 31417 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 31715 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 32012 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 32311 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 32611 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 32908 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 33207 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 33504 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 33802 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 34102 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 34401 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 34701 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 35000 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 35299 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 35597 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 35896 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 36194 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 36494 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 36792 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 37091 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 37389 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 37689 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 37986 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 38285 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 38584 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 38883 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 39180 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 39479 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 39778 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 40077 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 40376 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 40675 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 40972 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 41270 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 41569 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 41869 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 42169 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 42466 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 42766 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 43065 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 43365 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 43662 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 43962 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 44260 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 44560 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 44860 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 45159 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 45458 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 45757 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 46056 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 46355 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 46652 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 46952 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 47250 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 47549 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 47848 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 48147 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 48446 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 48746 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 49045 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 49343 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 49642 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 49942 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 50240 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 50538 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 50837 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 51134 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 51433 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 51729 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 52027 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 52327 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 52626 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 52924 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 53222 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 53522 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 53821 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 54119 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 54417 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 54716 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 55015 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 55313 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 55612 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 55912 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 56209 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 56507 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 56805 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 57105 / 199008\n",
      "New synthetic data generated: 295\n",
      "Number of fraud in the balanced dataset: 57400 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 57698 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 57996 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 58293 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 58593 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 58892 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 59192 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 59492 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 59790 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 60088 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 60385 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 60683 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 60983 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 61281 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 61581 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 61878 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 62178 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 62477 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 62777 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 63076 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 63374 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 63673 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 63973 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 64273 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 64572 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 64870 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 65167 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 65466 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 65766 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 66064 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 66363 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 66661 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 66961 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 67261 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 67559 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 67856 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 68155 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 68454 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 68754 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 69054 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 69354 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 69654 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 69954 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 70252 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 70551 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 70850 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 71148 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 71447 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 71747 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 72043 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 72341 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 72640 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 72939 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 73239 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 73538 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 73836 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 74134 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 74434 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 74733 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 75031 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 75331 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 75627 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 75927 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 76226 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 76523 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 76823 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 77123 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 77421 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 77720 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 78019 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 78318 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 78617 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 78917 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 79216 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 79514 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 79814 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 80112 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 80412 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 80709 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 81007 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 81305 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 81605 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 81903 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 82203 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 82502 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 82801 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 83099 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 83397 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 83696 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 83995 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 84294 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 84593 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 84892 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 85190 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 85489 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 85789 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 86089 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 86388 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 86688 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 86987 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 87285 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 87585 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 87884 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 88182 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 88480 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 88777 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 89075 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 89372 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 89670 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 89967 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 90266 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 90564 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 90862 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 91160 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 91460 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 91760 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 92059 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 92359 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 92656 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 92954 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 93254 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 93553 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 93853 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 94153 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 94452 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 94749 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 95048 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 95345 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 95643 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 95942 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 96239 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 96539 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 96839 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 97138 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 97437 / 199008\n",
      "New synthetic data generated: 295\n",
      "Number of fraud in the balanced dataset: 97732 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 98031 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 98330 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 98628 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 98925 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 99225 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 99525 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 99825 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 100122 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 100420 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 100718 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 101017 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 101317 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 101614 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 101910 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 102209 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 102507 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 102807 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 103106 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 103405 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 103704 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 104002 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 104302 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 104602 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 104901 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 105200 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 105500 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 105800 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 106099 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 106396 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 106696 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 106996 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 107295 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 107595 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 107894 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 108193 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 108493 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 108791 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 109089 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 109389 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 109688 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 109985 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 110285 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 110584 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 110884 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 111182 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 111480 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 111778 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 112076 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 112376 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 112676 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 112976 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 113275 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 113574 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 113874 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 114173 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 114470 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 114770 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 115070 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 115368 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 115668 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 115967 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 116267 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 116567 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 116867 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 117166 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 117465 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 117764 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 118063 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 118361 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 118660 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 118959 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 119259 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 119558 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 119857 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 120157 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 120457 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 120757 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 121056 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 121356 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 121654 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 121951 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 122250 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 122548 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 122846 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 123146 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 123446 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 123743 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 124042 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 124342 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 124641 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 124941 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 125240 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 125539 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 125839 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 126137 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 126435 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 126734 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 127033 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 127333 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 127632 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 127931 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 128229 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 128525 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 128824 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 129123 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 129421 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 129721 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 130020 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 130320 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 130620 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 130919 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 131218 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 131518 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 131817 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 132116 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 132415 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 132714 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 133014 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 133313 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 133613 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 133912 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 134211 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 134510 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 134808 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 135107 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 135405 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 135705 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 136003 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 136302 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 136601 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 136901 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 137201 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 137497 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 137797 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 138095 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 138393 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 138692 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 138992 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 139291 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 139590 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 139888 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 140188 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 140488 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 140787 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 141087 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 141387 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 141686 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 141985 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 142283 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 142583 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 142881 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 143180 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 143476 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 143773 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 144071 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 144370 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 144667 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 144967 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 145267 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 145565 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 145865 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 146163 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 146462 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 146760 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 147059 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 147359 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 147657 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 147956 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 148256 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 148555 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 148855 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 149154 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 149454 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 149754 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 150054 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 150351 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 150648 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 150948 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 151246 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 151545 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 151844 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 152142 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 152441 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 152741 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 153040 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 153340 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 153639 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 153938 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 154238 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 154537 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 154837 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 155137 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 155436 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 155736 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 156032 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 156332 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 156630 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 156929 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 157227 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 157524 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 157824 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 158124 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 158421 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 158720 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 159019 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 159319 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 159618 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 159915 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 160214 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 160514 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 160812 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 161112 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 161411 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 161707 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 162005 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 162304 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 162603 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 162903 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 163202 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 163501 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 163801 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 164099 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 164397 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 164696 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 164996 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 165295 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 165595 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 165894 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 166193 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 166492 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 166791 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 167090 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 167390 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 167690 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 167989 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 168289 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 168589 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 168888 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 169187 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 169486 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 169786 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 170086 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 170386 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 170684 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 170981 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 171281 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 171580 / 199008\n",
      "New synthetic data generated: 296\n",
      "Number of fraud in the balanced dataset: 171876 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 172175 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 172473 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 172772 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 173072 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 173370 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 173670 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 173970 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 174268 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 174567 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 174866 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 175163 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 175461 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 175760 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 176058 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 176357 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 176656 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 176955 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 177252 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 177552 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 177851 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 178150 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 178450 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 178749 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 179049 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 179348 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 179648 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 179947 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 180247 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 180547 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 180845 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 181143 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 181443 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 181740 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 182040 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 182337 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 182635 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 182934 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 183234 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 183532 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 183832 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 184132 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 184431 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 184731 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 185030 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 185330 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 185630 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 185928 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 186228 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 186527 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 186824 / 199008\n",
      "New synthetic data generated: 297\n",
      "Number of fraud in the balanced dataset: 187121 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 187421 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 187721 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 188021 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 188320 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 188620 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 188918 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 189218 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 189516 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 189815 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 190114 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 190413 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 190711 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 191010 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 191310 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 191610 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 191910 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 192209 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 192508 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 192807 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 193106 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 193404 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 193703 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 194002 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 194300 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 194598 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 194897 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 195197 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 195497 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 195796 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 196096 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 196395 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 196694 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 196994 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 197292 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 197592 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 197890 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 198190 / 199008\n",
      "New synthetic data generated: 300\n",
      "Number of fraud in the balanced dataset: 198490 / 199008\n",
      "New synthetic data generated: 299\n",
      "Number of fraud in the balanced dataset: 198789 / 199008\n",
      "New synthetic data generated: 298\n",
      "Number of fraud in the balanced dataset: 199087 / 199008\n",
      "Final shape of data: (398095, 30)\n",
      "Final # Fraud: 199087\n",
      "Final # Legit: 199008\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the ALSTM model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:26:15.458211Z",
     "start_time": "2025-02-28T06:26:15.448898Z"
    }
   },
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_weights = nn.Linear(hidden_size, 1, bias=False)\n",
    "        \n",
    "    def forward(self, lstm_output):\n",
    "        # Check if we need to add a sequence dimension\n",
    "        if len(lstm_output.shape) == 2:\n",
    "            # Add a sequence dimension of length 1\n",
    "            lstm_output = lstm_output.unsqueeze(1)\n",
    "            \n",
    "        # Now lstm_output should be (batch_size, seq_len, hidden_size)\n",
    "        attention_scores = self.attention_weights(lstm_output)  # (batch_size, seq_len, 1)\n",
    "        attention_scores = attention_scores.squeeze(-1)  # (batch_size, seq_len)\n",
    "        \n",
    "        # Apply softmax over sequence dimension\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (batch_size, seq_len)\n",
    "        \n",
    "        # Apply attention weights\n",
    "        context = torch.sum(lstm_output * attention_weights.unsqueeze(-1), dim=1)  # (batch_size, hidden_size)\n",
    "        \n",
    "        return context\n",
    "\n",
    "class ALSTM(nn.Module):\n",
    "    def __init__(self, input_size=30, hidden_size=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(hidden_size)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        lstm_out, (h, c) = self.lstm(x)\n",
    "        \n",
    "        # apply attention: \n",
    "        # (be sure your actual attention method expects lstm_out,h,c in that order)\n",
    "        context = self.attention(lstm_out)  # shape: (batch_size, hidden_size)\n",
    "        \n",
    "        # pass through linear layer\n",
    "        logits = self.fc(context)  # shape: (batch_size, 1)\n",
    "        \n",
    "        # apply sigmoid\n",
    "        out = self.sigmoid(logits) # shape: (batch_size, 1)\n",
    "        \n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:55:12.211806Z",
     "start_time": "2025-02-28T06:55:12.187474Z"
    }
   },
   "source": [
    "def train_model(model, X, y, num_epochs=100, batch_size=32, lr=0.001):\n",
    "    # define loss function and optimizer\n",
    "    criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # Adam optimizer\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.FloatTensor(y).reshape(-1, 1)  # Ensure proper shape\n",
    "\n",
    "    if X_tensor.dim() == 2:\n",
    "        X_tensor = X_tensor.unsqueeze(1)\n",
    "\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # train the model\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            \n",
    "            # Compute loss - both should be batch_size x 1\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Print progress\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}')\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gradient Boosting Classifier\n",
    "**Input:** Training set $T = \\{(x_i, y_i)\\}_{i=1}^m$, ALSTM as base learner, number of estimators $(n\\_estimators)$\n",
    "\n",
    "Initialize $h^0(x)$ with a constant: $h^0(x) = \\arg \\min \\sum_{i=1}^n L(y_i, 0)$\n",
    "\n",
    "**for** $t = 1, \\ldots, n\\_estimators$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute residuals: $r_i^t = -\\frac{\\partial L}{\\partial h^{t-1}(x_i)}$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Train $ALSTM_t(x)$ using the dataset $(x_i, r_i^t)$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Calculate step length: $\\alpha^t = \\arg \\min_\\alpha \\sum_{i=1}^n L(y_i, h^{t-1}(x_i) + \\alpha h^t(x_i))$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Update the model: $h(x) = h(x) + \\alpha^t h_t(x)$\n",
    "\n",
    "**end for**\n",
    "\n",
    "**Output:** Final ensemble model $h(x)$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T07:00:46.708487Z",
     "start_time": "2025-02-28T06:59:07.665010Z"
    }
   },
   "source": [
    "def GB_classifier(X, y, n_estimators=10):\n",
    "    estimators = []\n",
    "\n",
    "    loss_fn = lambda y, yhat: (1/2) * np.sum((y - yhat)**2)\n",
    "    \n",
<<<<<<< HEAD
    "    hx = np.argmin(loss_fn(y_i, 0) for y_i in y)\n",
    "\n",
=======
    "    # what is y_train?\n",
    "    hx = np.argmin([loss_fn(y, 0) for y in y_train])\n",
    "    \n",
    "    print(hx)\n",
>>>>>>> 9f7bb93d6194a6ed68b0f142ade7933cfedc3b94
    "    for t in range(n_estimators):\n",
    "        # compute the residual\n",
    "        residuals = y - hx\n",
    "\n",
    "        # train model using the dataset (x_i, residuals_i)\n",
    "        model_t = ALSTM(input_size=30, hidden_size=10)\n",
    "\n",
    "        train_model(model_t, X, residuals, num_epochs=2, batch_size=32)\n",
    "\n",
    "        # predict the residuals\n",
    "        model_t.eval()\n",
    "        with torch.no_grad():\n",
    "            # Convert input data to PyTorch tensor\n",
    "            X_tensor = torch.FloatTensor(X)\n",
    "            # Get model predictions\n",
    "            predictions = model_t(X_tensor)\n",
    "            # Convert predictions to numpy array\n",
    "            h_t = predictions.numpy().flatten()\n",
    "        \n",
    "        # compute step length\n",
    "        alpha_t = np.argmin(loss_fn(y, hx + alpha * h_t))\n",
    "        # maybe like this?\n",
    "        #numerator = np.sum(hx * (y - h_t))\n",
    "        #denominator = np.sum(hx ** 2)\n",
    "        #alpha_t = numerator / denominator if denominator != 0 else 0\n",
    "        print(alpha_t)\n",
    "        # update the predictions\n",
    "        hx += alpha_t * h_t\n",
    "\n",
    "        estimators.append((model_t, alpha_t))\n",
    "\n",
    "    return estimators"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T07:02:39.212047Z",
     "start_time": "2025-02-28T07:00:47.346309Z"
    }
   },
   "source": "estimators = GB_classifier(data_train_oversampled, labels_train_oversampled, n_estimators=6)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch [1/2], Loss: 0.0180\n",
      "Epoch [2/2], Loss: 0.0021\n",
      "0\n",
      "Epoch [1/2], Loss: 0.0163\n",
      "Epoch [2/2], Loss: 0.0019\n",
      "0\n",
      "Epoch [1/2], Loss: 0.0194\n",
      "Epoch [2/2], Loss: 0.0017\n",
      "0\n",
      "Epoch [1/2], Loss: 0.0170\n",
      "Epoch [2/2], Loss: 0.0019\n",
      "0\n",
      "Epoch [1/2], Loss: 0.0161\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[85], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m estimators \u001B[38;5;241m=\u001B[39m \u001B[43mGB_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_train_oversampled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_train_oversampled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_estimators\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[83], line 16\u001B[0m, in \u001B[0;36mGB_classifier\u001B[0;34m(X, y, n_estimators)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# train model using the dataset (x_i, residuals_i)\u001B[39;00m\n\u001B[1;32m     14\u001B[0m model_t \u001B[38;5;241m=\u001B[39m ALSTM(input_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, hidden_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresiduals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# predict the residuals\u001B[39;00m\n\u001B[1;32m     19\u001B[0m model_t\u001B[38;5;241m.\u001B[39meval()\n",
      "Cell \u001B[0;32mIn[76], line 32\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, X, y, num_epochs, batch_size, lr)\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;66;03m# Backward pass and optimize\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 32\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# Print progress\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    488\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    489\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    490\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    491\u001B[0m             )\n\u001B[0;32m--> 493\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    496\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/Desktop/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/adam.py:244\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    232\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    234\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    235\u001B[0m         group,\n\u001B[1;32m    236\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    241\u001B[0m         state_steps,\n\u001B[1;32m    242\u001B[0m     )\n\u001B[0;32m--> 244\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/Desktop/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/adam.py:876\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    873\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    874\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 876\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/adam.py:476\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    474\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 476\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    478\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[1;32m    480\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:28:14.710632Z",
     "start_time": "2025-02-28T06:28:14.588993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def predict_model(m, data):\n",
    "    m.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        X_tensor = torch.FloatTensor(data)  # Convert NumPy array to PyTorch tensor\n",
    "        \n",
    "        # If ALSTM expects 3D input, reshape to (batch, seq_len, features)\n",
    "        if len(X_tensor.shape) == 2:\n",
    "            X_tensor = X_tensor.unsqueeze(1)  # Adds sequence length dimension\n",
    "        predictions = m(X_tensor).squeeze().numpy() \n",
    "        return predictions\n",
    "    \n",
    "base_value = 0.5  # or store it somewhere else\n",
    "\n",
    "hx = np.full(data_test.shape[0], base_value, dtype=np.float32)\n",
    "\n",
    "for (m, alpha) in estimators:\n",
    "    print(alpha)\n",
    "    hx += alpha * predict_model(m, data_test)\n",
    "    \n",
    "\n",
    "# threshold at 0.5 for classification\n",
    "preds = np.where(hx > 0.5, 1, 0)\n",
    "accuracy = np.mean(preds == y_test)\n",
    "print(\"Final training accuracy:\", accuracy)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Final training accuracy: 0.9984082955888721\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T06:28:14.755603Z",
     "start_time": "2025-02-28T06:28:14.747592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute needed values for metrics calculations\n",
    "TP = np.sum((preds == 1) & (y_test == 1))  # TP\n",
    "FP = np.sum((preds == 1) & (y_test == 0))  # FP\n",
    "TN = np.sum((preds == 0) & (y_test == 0))  # TN\n",
    "FN = np.sum((preds == 0) & (y_test == 1))  # FN\n",
    "\n",
    "print(f\"True Positives: {TP}\")\n",
    "print(f\"False Positives: {FP}\")\n",
    "print(f\"True Negatives: {TN}\")\n",
    "print(f\"False Negatives: {FN}\")\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Print results\n",
    "print(f\"Final training accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0\n",
      "False Positives: 0\n",
      "True Negatives: 85307\n",
      "False Negatives: 136\n",
      "Final training accuracy: 0.9984\n",
      "Precision: nan\n",
      "Recall (Sensitivity): 0.0000\n",
      "Specificity: 1.0000\n",
      "F1-score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/kr80x6xj1rd1v8b13j6w6c880000gn/T/ipykernel_66945/3554743145.py:14: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = TP / (TP + FP)\n"
     ]
    }
   ],
   "execution_count": 73
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
