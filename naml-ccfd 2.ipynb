{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T13:22:57.741163Z",
     "iopub.status.busy": "2025-03-12T13:22:57.740789Z",
     "iopub.status.idle": "2025-03-12T13:23:03.108627Z",
     "shell.execute_reply": "2025-03-12T13:23:03.107928Z",
     "shell.execute_reply.started": "2025-03-12T13:22:57.741136Z"
    },
    "executionInfo": {
     "elapsed": 10891,
     "status": "ok",
     "timestamp": 1749799765242,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "4GFOQDetEfJu",
    "jupyter": {
     "is_executing": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:04.712947Z",
     "start_time": "2025-03-14T17:50:02.280839Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:23:03.110322Z",
     "iopub.status.busy": "2025-03-12T13:23:03.109803Z",
     "iopub.status.idle": "2025-03-12T13:23:06.808151Z",
     "shell.execute_reply": "2025-03-12T13:23:06.807423Z",
     "shell.execute_reply.started": "2025-03-12T13:23:03.110288Z"
    },
    "executionInfo": {
     "elapsed": 3666,
     "status": "ok",
     "timestamp": 1749799768925,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "Hx5MVt8jEfJv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Load and preprocess dataset\n",
    "# -----------------------------\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "data['Amount'] = RobustScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data['Time'] = RobustScaler().fit_transform(data['Time'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time'], axis=1)\n",
    "\n",
    "dataset = data.to_numpy().astype(np.float32)\n",
    "\n",
    "# divide the samples and the labels\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:04.890496Z",
     "start_time": "2025-03-14T17:50:04.847456Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1749799769065,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "PG269vnVEfJv",
    "outputId": "ed23b5a1-31a5-4863-fb23-c9f8638e9bb7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a pie chart to visualize the distribution of fraud vs. legitimate transactions\n",
    "# we see how fraud transactions are much less than legitimate ones\n",
    "\n",
    "fraud_count = np.bincount(y.astype(int))\n",
    "\n",
    "labels = [\"Legit\", \"Fraud\"]\n",
    "colors = [\"blue\", \"red\"]\n",
    "\n",
    "# Plotting as a pie chart\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(fraud_count, labels=labels, colors=colors, autopct=\"%1.1f%%\", startangle=90, shadow=False)\n",
    "plt.title(\"Fraud vs. Legitimate Transactions\")\n",
    "plt.axis(\"equal\")  # Equal aspect ratio to ensure the pie is circular\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:04.966005Z",
     "start_time": "2025-03-14T17:50:04.900062Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:23:06.815209Z",
     "iopub.status.busy": "2025-03-12T13:23:06.814960Z",
     "iopub.status.idle": "2025-03-12T13:23:06.900489Z",
     "shell.execute_reply": "2025-03-12T13:23:06.899757Z",
     "shell.execute_reply.started": "2025-03-12T13:23:06.815190Z"
    },
    "executionInfo": {
     "elapsed": 139,
     "status": "ok",
     "timestamp": 1749799769206,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "zmtTgRQtEfJw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split entire dataset into train and test\n",
    "data_train, data_test, label_train, label_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:05.022525Z",
     "start_time": "2025-03-14T17:50:05.017487Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:23:06.901597Z",
     "iopub.status.busy": "2025-03-12T13:23:06.901307Z",
     "iopub.status.idle": "2025-03-12T13:23:06.907770Z",
     "shell.execute_reply": "2025-03-12T13:23:06.907087Z",
     "shell.execute_reply.started": "2025-03-12T13:23:06.901567Z"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1749799769257,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "rWcuO95QEfJw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. Define the Autoencoder Model\n",
    "# -----------------------------\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder: 29 -> 23 -> 19 -> 17 -> 8\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(29, 23),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(23, 19),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(19, 17),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(17, 8)\n",
    "        )\n",
    "        # Decoder: 8 -> 17 -> 19 -> 23 -> 29 with Sigmoid at the end\n",
    "        # (Sigmoid is generally optional if you are using MSELoss and inputs are not strictly [0,1])\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 17),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(17, 19),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(19, 23),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(23, 29)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:05.874912Z",
     "start_time": "2025-03-14T17:50:05.114740Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:23:06.908739Z",
     "iopub.status.busy": "2025-03-12T13:23:06.908534Z",
     "iopub.status.idle": "2025-03-12T13:24:27.266122Z",
     "shell.execute_reply": "2025-03-12T13:24:27.265261Z",
     "shell.execute_reply.started": "2025-03-12T13:23:06.908708Z"
    },
    "executionInfo": {
     "elapsed": 10432,
     "status": "ok",
     "timestamp": 1749799779694,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "i3IHmxlqEfJw",
    "outputId": "511ccc07-2145-41c2-f241-373263d4ee2a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 29)\n",
      "Epoch 0, Train Loss: 26.1145, Val Loss: 29.6926\n",
      "Epoch 50, Train Loss: 8.9743, Val Loss: 7.5652\n",
      "Epoch 100, Train Loss: 7.8264, Val Loss: 7.3426\n",
      "Epoch 150, Train Loss: 7.6414, Val Loss: 7.4372\n",
      "Early stopping at epoch 183\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Extract fraud samples using label_train (1 = fraud)\n",
    "# -----------------------------\n",
    "# data_train and label_train are assumed to be already defined from your previous splitting.\n",
    "data_train_fraud = data_train[label_train == 1]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Train/Validation Split (80-20) on the fraud samples\n",
    "# -----------------------------\n",
    "data_train_autoencoder, test_data_autoencoder = train_test_split(data_train_fraud, test_size=0.2, random_state=32)\n",
    "\n",
    "print(data_train_autoencoder.shape)\n",
    "# Convert numpy arrays to PyTorch tensors (ensure float type)\n",
    "tensor_fraud_train = torch.from_numpy(data_train_autoencoder).float()\n",
    "tensor_fraud_val   = torch.from_numpy(test_data_autoencoder).float()\n",
    "\n",
    "# For an autoencoder, input equals target\n",
    "train_dataset = TensorDataset(tensor_fraud_train, tensor_fraud_train)\n",
    "val_dataset   = TensorDataset(tensor_fraud_val, tensor_fraud_val)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Initialize Model, Loss, Optimizer, and Scheduler\n",
    "# -----------------------------\n",
    "my_autoencoder = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()  # Using MSELoss now\n",
    "optimizer = optim.Adam(my_autoencoder.parameters(), lr=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500, eta_min=1e-6)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Training Loop with L1 Regularization and Validation Evaluation\n",
    "# -----------------------------\n",
    "num_epochs = 2000\n",
    "history_loss_train = []\n",
    "history_loss_val   = []\n",
    "patience = 75\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "l1_lambda = 5e-3  # L1 regularization strength\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    my_autoencoder.train()\n",
    "    running_loss_train = 0.0\n",
    "    for batch_x, _ in train_loader:\n",
    "        inputs = batch_x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = my_autoencoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        # Compute L1 norm of the model parameters\n",
    "        l1_norm = sum(p.abs().sum() for p in my_autoencoder.parameters())\n",
    "        loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss_train += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss_train = running_loss_train / len(train_loader.dataset)\n",
    "    history_loss_train.append(epoch_loss_train)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    my_autoencoder.eval()\n",
    "    running_loss_val = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, _ in val_loader:\n",
    "            inputs = batch_x.to(device)\n",
    "            outputs = my_autoencoder(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            running_loss_val += loss.item() * inputs.size(0)\n",
    "    epoch_loss_val = running_loss_val / len(val_loader.dataset)\n",
    "    history_loss_val.append(epoch_loss_val)\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_loss_val < best_val_loss:\n",
    "        best_val_loss = epoch_loss_val\n",
    "        best_model_state = my_autoencoder.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        my_autoencoder.load_state_dict(best_model_state)\n",
    "        break\n",
    "\n",
    "    # Optionally step the scheduler\n",
    "    # scheduler.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {epoch_loss_train:.4f}, Val Loss: {epoch_loss_val:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(my_autoencoder.state_dict(), \"autoencoder.pth\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Plot Training & Validation Loss\n",
    "# -----------------------------\n",
    "plt.figure()\n",
    "plt.plot(history_loss_train, label='Train Loss')\n",
    "plt.plot(history_loss_val, label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Log Scale)\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:05.915305Z",
     "start_time": "2025-03-14T17:50:05.881295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:24:27.267459Z",
     "iopub.status.busy": "2025-03-12T13:24:27.267025Z",
     "iopub.status.idle": "2025-03-12T13:24:27.299732Z",
     "shell.execute_reply": "2025-03-12T13:24:27.298888Z",
     "shell.execute_reply.started": "2025-03-12T13:24:27.267422Z"
    },
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1749799780399,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "6ghri86ZEfJx",
    "outputId": "612452cf-34c9-44d7-9cf2-0686c748ffc8",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9420\n",
      "Test Accuracy: 0.9510\n"
     ]
    }
   ],
   "source": [
    "# create the balanced dataset to train the SVM model\n",
    "data_train_non_fraud = data_train[label_train == 0][:len(data_train_fraud)]\n",
    "\n",
    "# Combine the selected data\n",
    "X_balanced_SVM = np.vstack((data_train_non_fraud, data_train_fraud))\n",
    "y_balanced_SVM = np.hstack((np.zeros(len(data_train_fraud)), np.ones(len(data_train_fraud))))  # Create labels: 0 for non-fraud, 1 for fraud\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_idx = np.random.permutation(len(X_balanced_SVM))\n",
    "X_balanced_SVM = X_balanced_SVM[shuffle_idx]\n",
    "y_balanced_SVM = y_balanced_SVM[shuffle_idx]\n",
    "\n",
    "# Split into training and test sets for SVM\n",
    "data_train_SVM, data_test_SVM, label_train_SVM, label_test_SVM = train_test_split(X_balanced_SVM, y_balanced_SVM, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM model for validation in the oversampling process\n",
    "my_svm = SVC(kernel='linear', C=1.0)\n",
    "my_svm.fit(data_train_SVM, label_train_SVM)\n",
    "\n",
    "# Get predictions and accuracy\n",
    "label_pred_test = my_svm.predict(data_test_SVM)\n",
    "label_pred_train = my_svm.predict(data_train_SVM)\n",
    "accuracy_train = np.mean(label_pred_train == label_train_SVM)\n",
    "accuracy_test = np.mean(label_pred_test == label_test_SVM)\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:11.572150Z",
     "start_time": "2025-03-14T17:50:05.971131Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55284,
     "status": "ok",
     "timestamp": 1749799835690,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "sI98NEF6EfJx",
    "outputId": "73ff4dcf-830f-437e-950a-b4547a1a2923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial counts - Fraud: 356, Non-fraud: 199008\n",
      "Added 294 synthetic fraud samples\n",
      "Fraud / Legit count: 650 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 949 / 199008\n",
      "Added 297 synthetic fraud samples\n",
      "Fraud / Legit count: 1246 / 199008\n",
      "Added 297 synthetic fraud samples\n",
      "Fraud / Legit count: 1543 / 199008\n",
      "Added 298 synthetic fraud samples\n",
      "Fraud / Legit count: 1841 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 2140 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 2440 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 2739 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 3039 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 3339 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 3639 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 3938 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 4237 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 4537 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 4837 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 5136 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 5436 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 5736 / 199008\n",
      "Added 298 synthetic fraud samples\n",
      "Fraud / Legit count: 6034 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 6334 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 6633 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 6933 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 7233 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 7533 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 7833 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 8132 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 8432 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 8732 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 9031 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 9331 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 9631 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 9931 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 10231 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 10531 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 10831 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 11131 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 11431 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 11731 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 12031 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 12331 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 12631 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 12930 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 13230 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 13530 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 13830 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 14129 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 14429 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 14729 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 15029 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 15329 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 15629 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 15929 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 16229 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 16529 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 16829 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 17129 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 17429 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 17729 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 18029 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 18329 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 18629 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 18929 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 19229 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 19529 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 19829 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 20129 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 20429 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 20729 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 21029 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 21329 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 21629 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 21928 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 22228 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 22528 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 22828 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 23128 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 23428 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 23728 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 24028 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 24327 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 24627 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 24927 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 25227 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 25527 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 25827 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 26127 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 26427 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 26727 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 27027 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 27327 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 27626 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 27926 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 28226 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 28526 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 28826 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 29126 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 29426 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 29726 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 30026 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 30326 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 30626 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 30926 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 31226 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 31526 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 31826 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 32125 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 32425 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 32725 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 33025 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 33325 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 33625 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 33925 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 34225 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 34525 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 34825 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 35125 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 35425 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 35725 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 36025 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 36325 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 36625 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 36925 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 37224 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 37524 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 37823 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 38123 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 38423 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 38723 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 39023 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 39322 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 39622 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 39922 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 40222 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 40522 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 40822 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 41122 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 41422 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 41722 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 42022 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 42322 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 42622 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 42922 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 43222 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 43522 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 43822 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 44122 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 44422 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 44722 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 45022 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 45322 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 45622 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 45922 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 46222 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 46521 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 46821 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 47121 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 47421 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 47721 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 48021 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 48321 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 48620 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 48920 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 49220 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 49520 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 49820 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 50120 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 50420 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 50719 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 51019 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 51319 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 51619 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 51919 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 52219 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 52519 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 52819 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 53119 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 53418 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 53718 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 54018 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 54318 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 54618 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 54918 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 55218 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 55518 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 55817 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 56117 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 56417 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 56717 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 57017 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 57317 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 57617 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 57917 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 58217 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 58517 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 58817 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 59116 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 59416 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 59716 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 60015 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 60315 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 60615 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 60915 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 61215 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 61515 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 61815 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 62115 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 62415 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 62715 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 63015 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 63315 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 63614 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 63914 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 64214 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 64514 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 64814 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 65114 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 65414 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 65714 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 66014 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 66314 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 66614 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 66914 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 67214 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 67514 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 67814 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 68114 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 68414 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 68714 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 69014 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 69314 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 69614 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 69914 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 70214 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 70514 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 70814 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 71114 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 71414 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 71714 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 72014 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 72314 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 72614 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 72914 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 73214 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 73513 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 73813 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 74113 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 74413 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 74713 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 75013 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 75313 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 75613 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 75913 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 76213 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 76513 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 76813 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 77113 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 77413 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 77713 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 78013 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 78312 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 78612 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 78912 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 79212 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 79512 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 79812 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 80112 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 80412 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 80712 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 81012 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 81312 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 81612 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 81912 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 82212 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 82512 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 82812 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 83112 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 83412 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 83712 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 84012 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 84312 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 84612 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 84912 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 85212 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 85512 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 85812 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 86112 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 86412 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 86712 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 87012 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 87312 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 87612 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 87912 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 88212 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 88512 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 88812 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 89112 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 89412 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 89711 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 90011 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 90311 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 90611 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 90911 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 91211 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 91510 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 91810 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 92110 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 92410 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 92710 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 93010 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 93310 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 93610 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 93910 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 94210 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 94510 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 94810 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 95110 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 95410 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 95710 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 96010 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 96310 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 96610 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 96910 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 97209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 97509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 97809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 98109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 98409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 98709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 99009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 99309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 99609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 99909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 100209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 100509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 100809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 101109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 101409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 101709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 102009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 102309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 102609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 102909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 103209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 103509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 103809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 104109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 104409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 104709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 105009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 105309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 105609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 105909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 106209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 106509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 106809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 107109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 107409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 107709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 108009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 108309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 108609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 108909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 109209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 109509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 109809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 110109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 110409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 110709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 111009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 111309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 111609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 111909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 112209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 112509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 112809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 113109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 113409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 113709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 114009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 114309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 114609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 114909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 115209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 115509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 115809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 116109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 116409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 116709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 117009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 117309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 117609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 117909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 118209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 118509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 118809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 119109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 119409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 119709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 120009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 120309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 120609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 120909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 121209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 121509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 121809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 122109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 122409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 122709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 123009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 123309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 123609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 123909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 124209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 124509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 124809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 125109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 125409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 125709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 126009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 126309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 126609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 126909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 127209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 127509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 127809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 128109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 128409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 128709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 129009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 129309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 129609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 129909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 130209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 130509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 130809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 131109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 131409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 131709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 132009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 132309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 132609 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 132909 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 133209 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 133509 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 133809 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 134109 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 134409 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 134709 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 135009 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 135309 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 135609 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 135908 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 136207 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 136507 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 136807 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 137107 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 137407 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 137707 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 138007 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 138307 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 138607 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 138907 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 139207 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 139507 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 139807 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 140107 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 140407 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 140707 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 141007 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 141307 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 141607 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 141907 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 142207 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 142507 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 142807 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 143107 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 143407 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 143707 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 144007 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 144307 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 144607 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 144907 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 145207 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 145507 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 145807 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 146107 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 146407 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 146707 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 147007 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 147307 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 147607 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 147907 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 148207 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 148507 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 148807 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 149107 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 149407 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 149707 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 150007 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 150306 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 150606 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 150906 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 151206 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 151506 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 151805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 152105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 152405 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 152705 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 153005 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 153305 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 153605 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 153905 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 154205 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 154505 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 154805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 155105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 155405 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 155705 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 156005 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 156305 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 156605 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 156905 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 157205 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 157505 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 157805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 158105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 158405 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 158705 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 159005 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 159305 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 159605 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 159905 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 160205 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 160505 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 160805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 161105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 161405 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 161705 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 162005 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 162305 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 162605 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 162905 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 163205 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 163505 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 163805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 164105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 164405 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 164705 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 165005 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 165305 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 165605 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 165905 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 166205 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 166505 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 166805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 167105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 167405 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 167705 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 168005 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 168305 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 168605 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 168905 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 169205 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 169505 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 169805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 170105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 170405 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 170705 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 171005 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 171305 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 171605 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 171905 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 172205 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 172505 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 172805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 173105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 173405 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 173705 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 174005 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 174305 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 174605 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 174905 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 175205 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 175505 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 175805 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 176105 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 176405 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 176704 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 177004 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 177304 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 177604 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 177904 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 178204 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 178504 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 178804 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 179104 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 179404 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 179704 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 180004 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 180304 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 180604 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 180904 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 181204 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 181504 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 181804 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 182104 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 182404 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 182704 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 183004 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 183304 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 183604 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 183904 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 184204 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 184504 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 184804 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 185104 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 185404 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 185704 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 186004 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 186304 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 186604 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 186904 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 187204 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 187504 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 187804 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 188104 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 188404 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 188704 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 189004 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 189304 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 189604 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 189904 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 190204 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 190504 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 190804 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 191104 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 191404 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 191704 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 192004 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 192304 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 192604 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 192904 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 193204 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 193504 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 193804 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 194104 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 194404 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 194704 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 195004 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 195304 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 195604 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 195904 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 196204 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 196504 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 196804 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 197104 / 199008\n",
      "Added 299 synthetic fraud samples\n",
      "Fraud / Legit count: 197403 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 197703 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 198003 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 198303 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 198603 / 199008\n",
      "Added 300 synthetic fraud samples\n",
      "Fraud / Legit count: 198903 / 199008\n",
      "Added 105 synthetic fraud samples\n",
      "Fraud / Legit count: 199008 / 199008\n",
      "\n",
      "Final shape of data: (398016, 29)\n",
      "Final # Fraud: 199008\n",
      "Final # Legit: 199008\n"
     ]
    }
   ],
   "source": [
    "def get_fraud_indices(labels):\n",
    "    \"\"\"Return indices for which label == 1.\"\"\"\n",
    "    return np.where(labels == 1)[0]\n",
    "\n",
    "def get_legit_indices(labels):\n",
    "    \"\"\"Return indices for which label == 0.\"\"\"\n",
    "    return np.where(labels == 0)[0]\n",
    "\n",
    "# Make your copies to oversample\n",
    "oversampled_data = data_train.copy()\n",
    "oversampled_labels = label_train.copy()\n",
    "\n",
    "# For oversampling, we want to add synthetic fraud samples until fraud count equals non-fraud count.\n",
    "non_fraud_count = np.sum(oversampled_labels == 0)\n",
    "fraud_count = np.sum(oversampled_labels == 1)\n",
    "print(f\"Initial counts - Fraud: {fraud_count}, Non-fraud: {non_fraud_count}\")\n",
    "\n",
    "# Number of synthetic samples to generate per iteration and noise std\n",
    "n_samples_per_iter = 300\n",
    "\n",
    "# Use only the original fraud samples (from the training set) as the basis for synthetic data generation.\n",
    "original_fraud_data = data_train[label_train == 1]\n",
    "original_fraud_data_tensor = torch.tensor(original_fraud_data, dtype=torch.float32)\n",
    "\n",
    "# Ensure the autoencoder is in evaluation mode\n",
    "my_autoencoder.eval()\n",
    "\n",
    "alpha = 0.9\n",
    "\n",
    "while len(get_fraud_indices(oversampled_labels)) < len(get_legit_indices(oversampled_labels)):\n",
    "    fraud_indices = get_fraud_indices(oversampled_labels)\n",
    "    legit_count = len(get_legit_indices(oversampled_labels))\n",
    "    fraud_count = len(fraud_indices)\n",
    "    remaining_needed = legit_count - fraud_count\n",
    "\n",
    "    if fraud_count == 0:\n",
    "        print(\"No fraud data found. Cannot proceed with oversampling.\")\n",
    "        break\n",
    "\n",
    "    # 1) Gather all fraud samples\n",
    "    fraud_only_X = oversampled_data[fraud_indices, :]\n",
    "    fraud_data_tensor = torch.tensor(fraud_only_X, dtype=torch.float32)\n",
    "\n",
    "    # 2) Encode to latent space\n",
    "    latent_representations = my_autoencoder.encoder(fraud_data_tensor)\n",
    "    n = len(latent_representations)\n",
    "    if n == 0:\n",
    "        print(\"Error: no latent representations. Check input data.\")\n",
    "        break\n",
    "\n",
    "    # 3) Interpolate in latent space + add noise\n",
    "    noisy_vectors = []\n",
    "    for _ in range(300):  # You can reduce this if too many are generated\n",
    "        i = np.random.randint(0, n)\n",
    "        j = np.random.randint(0, n)\n",
    "\n",
    "        z_i = latent_representations[i]\n",
    "        z_j = latent_representations[j]\n",
    "\n",
    "        lambda_ = np.random.rand()\n",
    "        z_ij = lambda_ * z_i + (1 - lambda_) * z_j\n",
    "\n",
    "        noise = torch.normal(mean=0.0, std=alpha, size=z_ij.shape)\n",
    "        z_syn = z_ij + noise\n",
    "\n",
    "        noisy_vectors.append(z_syn.detach().cpu().numpy())\n",
    "\n",
    "    noisy_vectors = np.array(noisy_vectors)\n",
    "\n",
    "    latent_reps = np.array(latent_representations.detach().cpu().numpy())\n",
    "    # 4) Decode to original 30-dim space\n",
    "    X_synthetic = my_autoencoder.decoder(    torch.tensor(noisy_vectors, dtype=torch.float32)).detach().cpu().numpy()\n",
    "\n",
    "    #with torch.no_grad():\n",
    "        #X_synthetic = my_autoencoder(original_fraud_data_tensor).cpu().numpy()\n",
    "    # 5) Classify with SVM\n",
    "    y_pred = my_svm.predict(X_synthetic)\n",
    "\n",
    "    # 6) Keep only predicted fraud\n",
    "    synthetic_fraud_mask = (y_pred == 1)\n",
    "    X_synthetic_fraud = X_synthetic[synthetic_fraud_mask]\n",
    "    y_synthetic_fraud = y_pred[synthetic_fraud_mask]\n",
    "\n",
    "    # 7) Limit the number of fraud samples added to only what is needed\n",
    "    max_add = min(len(X_synthetic_fraud), remaining_needed)\n",
    "    if max_add <= 0:\n",
    "        break  # done\n",
    "\n",
    "    oversampled_data = np.vstack((oversampled_data, X_synthetic_fraud[:max_add]))\n",
    "    oversampled_labels = np.hstack((oversampled_labels, y_synthetic_fraud[:max_add]))\n",
    "\n",
    "    n_fraud = len(get_fraud_indices(oversampled_labels))\n",
    "    n_legit = len(get_legit_indices(oversampled_labels))\n",
    "    print(f\"Added {max_add} synthetic fraud samples\")\n",
    "    print(f\"Fraud / Legit count: {n_fraud} / {n_legit}\")\n",
    "\n",
    "print(\"\\nFinal shape of data:\", oversampled_data.shape)\n",
    "print(\"Final # Fraud:\", len(get_fraud_indices(oversampled_labels)))\n",
    "print(\"Final # Legit:\", len(get_legit_indices(oversampled_labels)))\n",
    "\n",
    "# Save the balanced data\n",
    "# np.save(\"data_train_balanced.npy\", oversampled_data)\n",
    "# np.save(\"y_train_balanced.npy\", oversampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:11.775446Z",
     "start_time": "2025-03-14T17:50:11.766452Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:25:14.433599Z",
     "iopub.status.busy": "2025-03-12T13:25:14.433196Z",
     "iopub.status.idle": "2025-03-12T13:25:25.722776Z",
     "shell.execute_reply": "2025-03-12T13:25:25.721947Z",
     "shell.execute_reply.started": "2025-03-12T13:25:14.433577Z"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1749799872929,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "MVJW2E0bEfJx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")\n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=tf.squeeze(tf.tanh(tf.linalg.matmul(x,self.W)+self.b),axis=-1)\n",
    "        at=tf.nn.softmax(et)\n",
    "        at=tf.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return tf.reduce_sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n",
    "\n",
    "def create_ALSTM_model():\n",
    "    inputs1=Input((1,29))\n",
    "    att_in=LSTM(50,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(inputs1)\n",
    "    att_in_1=LSTM(50,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(att_in)\n",
    "    att_out=attention()(att_in_1)\n",
    "    outputs1=Dense(1,activation='sigmoid',trainable=True)(att_out)\n",
    "    model1=Model(inputs1,outputs1)\n",
    "\n",
    "    model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749799872930,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "pJ2V7Ht8--Av"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:50:11.828993Z",
     "start_time": "2025-03-14T17:50:11.822399Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:25:25.724182Z",
     "iopub.status.busy": "2025-03-12T13:25:25.723667Z",
     "iopub.status.idle": "2025-03-12T13:25:25.732975Z",
     "shell.execute_reply": "2025-03-12T13:25:25.732083Z",
     "shell.execute_reply.started": "2025-03-12T13:25:25.724158Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749799872931,
     "user": {
      "displayName": "Beatrice",
      "userId": "01616805708090823533"
     },
     "user_tz": -120
    },
    "id": "18BoXzQaEfJx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "# --- Adjusted training function using Keras without a validation dataset ---\n",
    "def train_model(model, X, y, num_epochs=2, batch_size=128):\n",
    "    # Ensure X has shape (num_samples, 1, 30)\n",
    "    if X.ndim == 2:\n",
    "        X_train = X.reshape(-1, 1, X.shape[1])\n",
    "    else:\n",
    "        X_train = X\n",
    "\n",
    "    # Train the model using Keras' fit without validation monitoring\n",
    "    history = model.fit(X_train, y, epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
    "    return model\n",
    "\n",
    "def GB_classifier(X, y, n_estimators=10):\n",
    "    estimators = []\n",
    "\n",
    "    # Define squared-error loss (for evaluating the ensemble)\n",
    "    loss_fn = lambda y_true, y_pred: 0.5 * np.sum((y_true - y_pred)**2)\n",
    "\n",
    "    # Initialize ensemble predictions for training data\n",
    "    hx = np.full(len(y), 0, dtype=np.float32)\n",
    "\n",
    "    for t in range(n_estimators):\n",
    "        # Compute training residuals: true labels minus current ensemble predictions\n",
    "        p = sigmoid(hx)\n",
    "        residuals = y - p\n",
    "\n",
    "        # Create a new instance of the Keras ALSTM model\n",
    "        model_t = create_ALSTM_model()\n",
    "\n",
    "        # Train the model on (X, residuals)\n",
    "        train_model(model_t, X, residuals, num_epochs=2, batch_size=128)\n",
    "\n",
    "        # Predict the current weak learner's output h_t on the training set.\n",
    "        X_input = X.reshape(-1, 1, X.shape[1]) if X.ndim == 2 else X\n",
    "        predictions = model_t.predict(X_input)\n",
    "        h_t = predictions.flatten()\n",
    "\n",
    "        # Use line search to determine the optimal step length alpha\n",
    "        def loss_func(alpha):\n",
    "            hx_new = hx + alpha * predictions\n",
    "            p_new = 1 / (1 + np.exp(-hx_new))\n",
    "            return -np.mean(y * np.log(p_new + 1e-7) + (1 - y) * np.log(1 - p_new + 1e-7))\n",
    "\n",
    "        alpha_t = np.float32(minimize_scalar(loss_func, method=\"golden\").x)\n",
    "        hx += alpha_t * predictions\n",
    "\n",
    "        # Update the ensemble predictions for training data\n",
    "        #hx += alpha_t * h_t\n",
    "\n",
    "        print(f\"a_{t+1} = {alpha_t:.4f}\")\n",
    "        print(f\"hx_{t+1} = {hx}\")\n",
    "\n",
    "        estimators.append((model_t, alpha_t))\n",
    "        clear_session()\n",
    "\n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:52:34.598520Z",
     "start_time": "2025-03-14T17:50:11.877600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:25:25.734291Z",
     "iopub.status.busy": "2025-03-12T13:25:25.733963Z",
     "iopub.status.idle": "2025-03-12T13:33:26.622602Z",
     "shell.execute_reply": "2025-03-12T13:33:26.621803Z",
     "shell.execute_reply.started": "2025-03-12T13:25:25.734260Z"
    },
    "id": "1Hu_l2VeEfJx",
    "outputId": "3665b892-e574-4987-fed8-4580bdaf5e3e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m3110/3110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -10.1955\n",
      "Epoch 2/2\n",
      "\u001b[1m3110/3110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: -42.3610\n",
      "\u001b[1m12438/12438\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.15 TiB for an array with shape (398016, 398016) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m estimators = \u001b[43mGB_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43moversampled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moversampled_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mGB_classifier\u001b[39m\u001b[34m(X, y, n_estimators)\u001b[39m\n\u001b[32m     44\u001b[39m     p_new = \u001b[32m1\u001b[39m / (\u001b[32m1\u001b[39m + np.exp(-hx_new))\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -np.mean(y * np.log(p_new + \u001b[32m1e-7\u001b[39m) + (\u001b[32m1\u001b[39m - y) * np.log(\u001b[32m1\u001b[39m - p_new + \u001b[32m1e-7\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m alpha_t = np.float32(\u001b[43mminimize_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgolden\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.x)\n\u001b[32m     48\u001b[39m hx += alpha_t * predictions\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Update the ensemble predictions for training data\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m#hx += alpha_t * h_t\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicco\\miniconda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:983\u001b[39m, in \u001b[36mminimize_scalar\u001b[39m\u001b[34m(fun, bracket, bounds, args, method, tol, options)\u001b[39m\n\u001b[32m    981\u001b[39m     res = _minimize_scalar_bounded(fun, bounds, args, **options)\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mgolden\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     res = \u001b[43m_recover_from_bracket_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_minimize_scalar_golden\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnknown solver \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicco\\miniconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:3098\u001b[39m, in \u001b[36m_recover_from_bracket_error\u001b[39m\u001b[34m(solver, fun, bracket, args, **options)\u001b[39m\n\u001b[32m   3079\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_recover_from_bracket_error\u001b[39m(solver, fun, bracket, args, **options):\n\u001b[32m   3080\u001b[39m     \u001b[38;5;66;03m# `bracket` was originally written without checking whether the resulting\u001b[39;00m\n\u001b[32m   3081\u001b[39m     \u001b[38;5;66;03m# bracket is valid. `brent` and `golden` built on top of it without\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3095\u001b[39m     \u001b[38;5;66;03m# storing the information needed by `minimize_scalar` in the error object,\u001b[39;00m\n\u001b[32m   3096\u001b[39m     \u001b[38;5;66;03m# and intercepting it here.\u001b[39;00m\n\u001b[32m   3097\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3098\u001b[39m         res = \u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3099\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m BracketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3100\u001b[39m         msg = \u001b[38;5;28mstr\u001b[39m(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicco\\miniconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:2820\u001b[39m, in \u001b[36m_minimize_scalar_golden\u001b[39m\u001b[34m(func, brack, args, xtol, maxiter, disp, **unknown_options)\u001b[39m\n\u001b[32m   2818\u001b[39m tol = xtol\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m brack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2820\u001b[39m     xa, xb, xc, fa, fb, fc, funcalls = \u001b[43mbracket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2821\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(brack) == \u001b[32m2\u001b[39m:\n\u001b[32m   2822\u001b[39m     xa, xb, xc, fa, fb, fc, funcalls = bracket(func, xa=brack[\u001b[32m0\u001b[39m],\n\u001b[32m   2823\u001b[39m                                                xb=brack[\u001b[32m1\u001b[39m], args=args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicco\\miniconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:2994\u001b[39m, in \u001b[36mbracket\u001b[39m\u001b[34m(func, xa, xb, args, grow_limit, maxiter)\u001b[39m\n\u001b[32m   2992\u001b[39m \u001b[38;5;66;03m# convert to numpy floats if not already\u001b[39;00m\n\u001b[32m   2993\u001b[39m xa, xb = np.asarray([xa, xb])\n\u001b[32m-> \u001b[39m\u001b[32m2994\u001b[39m fa = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2995\u001b[39m fb = func(*(xb,) + args)\n\u001b[32m   2996\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (fa < fb):                      \u001b[38;5;66;03m# Switch so fa > fb\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mGB_classifier.<locals>.loss_func\u001b[39m\u001b[34m(alpha)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mloss_func\u001b[39m(alpha):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     hx_new = \u001b[43mhx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\n\u001b[32m     44\u001b[39m     p_new = \u001b[32m1\u001b[39m / (\u001b[32m1\u001b[39m + np.exp(-hx_new))\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -np.mean(y * np.log(p_new + \u001b[32m1e-7\u001b[39m) + (\u001b[32m1\u001b[39m - y) * np.log(\u001b[32m1\u001b[39m - p_new + \u001b[32m1e-7\u001b[39m))\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 1.15 TiB for an array with shape (398016, 398016) and data type float64"
     ]
    }
   ],
   "source": [
    "estimators = GB_classifier(oversampled_data, oversampled_labels, n_estimators=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:52:44.068443Z",
     "start_time": "2025-03-14T17:52:34.830331Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:33:26.623856Z",
     "iopub.status.busy": "2025-03-12T13:33:26.623510Z",
     "iopub.status.idle": "2025-03-12T13:34:04.959850Z",
     "shell.execute_reply": "2025-03-12T13:34:04.958979Z",
     "shell.execute_reply.started": "2025-03-12T13:33:26.623807Z"
    },
    "id": "c1qHxEPVEfJx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Assuming data_test and label_test are defined from your earlier train_test_split\n",
    "# Ensure data_test has shape (n_samples, 1, 30) if needed by the model\n",
    "if data_test.ndim == 2:\n",
    "    data_test_input = data_test.reshape(-1, 1, data_test.shape[1])\n",
    "else:\n",
    "    data_test_input = data_test\n",
    "\n",
    "hx = np.full(len(data_test_input), 0, dtype=np.float32)\n",
    "\n",
    "# Go through each model in the trained ensemble\n",
    "for model, alpha in estimators:\n",
    "    prediction = model.predict(data_test_input).flatten()\n",
    "    hx += alpha * prediction\n",
    "\n",
    "\n",
    "# Threshold the accumulated predictions to get binary outputs\n",
    "y_pred = sigmoid(hx)\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(label_test, y_pred_binary)\n",
    "recall = recall_score(label_test, y_pred_binary)\n",
    "f1 = f1_score(label_test, y_pred_binary)\n",
    "accuracy = accuracy_score(label_test, y_pred_binary)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:52:44.273444Z",
     "start_time": "2025-03-14T17:52:44.091292Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T13:34:04.961069Z",
     "iopub.status.busy": "2025-03-12T13:34:04.960728Z",
     "iopub.status.idle": "2025-03-12T13:34:05.717998Z",
     "shell.execute_reply": "2025-03-12T13:34:05.717287Z",
     "shell.execute_reply.started": "2025-03-12T13:34:04.961035Z"
    },
    "id": "Fim9K0VyEfJy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add after your existing metrics\n",
    "cm = confusion_matrix(label_test, y_pred_binary)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:52:44.378510Z",
     "start_time": "2025-03-14T17:52:44.372750Z"
    },
    "id": "rdyuIoW_EfJy"
   },
   "outputs": [],
   "source": [
    "# (TP) shows how many fraud samples were successfully categorized.\n",
    "TP = np.sum((label_test == 1) & (y_pred_binary == 1))\n",
    "# (FP) refers to the number of legitimate samples that were incorrectly categorized.\n",
    "FP = np.sum((label_test == 0) & (y_pred_binary == 1))\n",
    "# (FN) shows how many fraud samples were missed.\n",
    "FN = np.sum((label_test == 1) & (y_pred_binary == 0))\n",
    "# (TN) refers to the number of legitimate samples that were correctly categorized.\n",
    "TN = np.sum((label_test == 0) & (y_pred_binary == 0))\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "specificity = TP / (FN + TP)\n",
    "precision = TP / (FP + TP)\n",
    "recall = TN / (TN + FP)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:52:44.432721Z",
     "start_time": "2025-03-14T17:52:44.429906Z"
    },
    "id": "0SFJp6XuEfJy"
   },
   "outputs": [],
   "source": [
    "# correct metrics found online\n",
    "\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "precision = TP / (TP + FP + 1e-7)\n",
    "recall = TP / (TP + FN + 1e-7)\n",
    "specificity = TN / (TN + FP + 1e-7)\n",
    "f1 = 2 * precision * recall / (precision + recall + 1e-7)\n",
    "\n",
    "print(f\"Accuracy    : {accuracy:.4f}\")\n",
    "print(f\"Precision   : {precision:.4f}\")\n",
    "print(f\"Recall      : {recall:.4f}\")\n",
    "print(f\"Specificity : {specificity:.4f}\")\n",
    "print(f\"F1 Score    : {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
